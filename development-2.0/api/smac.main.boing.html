
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>smac.main.boing &#8212; SMAC3 Documentation 2.0.0 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ac9c05f7c49ca1e1f876c6e36360ea26.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.9ea38e314b9e6d9dab77.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="smac.main.smbo" href="smac.main.smbo.html" />
    <link rel="prev" title="smac.main.base_smbo" href="smac.main.base_smbo.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
  <a class="navbar-brand" href="../index.html">
    <img src="../_static/logo.png" class="logo" alt="logo">
  </a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/https://github.com/automl/SMAC3" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/automl_org?lang=de" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search align-items-center" action="../search.html" method="get"
style="width: 100%;">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>

      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><h4 class="mt-0 mb-0"><a href="../index.html">SMAC3 Documentation</a></h4>
<div class="mb-3">v2.0.0</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../package_overview.html">
   Package Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../minimal_example.html">
   Minimal Example
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/1_basics/index.html">
     Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/2_multi_fidelity/index.html">
     Multi-Fidelity and Multi-Instances
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/3_multi_objective/index.html">
     Multi-Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/4_commandline/index.html">
     Commandline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../advanced_usage/index.html">
   Advanced Usage
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../advanced_usage/resumption.html">
     Resumption
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../advanced_usage/callbacks.html">
     Callbacks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../api.html">
   API References
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="smac.facade.html">
     smac.facade
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="reference internal" href="smac.main.html">
     smac.main
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.model.html">
     smac.model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.acquisition.html">
     smac.acquisition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.intensification.html">
     smac.intensification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.initial_design.html">
     smac.initial_design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.random_design.html">
     smac.random_design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.runner.html">
     smac.runner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.runhistory.html">
     smac.runhistory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.multi_objective.html">
     smac.multi_objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.utils.html">
     smac.utils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.scenario.html">
     smac.scenario
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.constants.html">
     smac.constants
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="smac.callback.html">
     smac.callback
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../faq.html">
   F.A.Q.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../license.html">
   License
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="module-smac.main.boing">
<span id="smac-main-boing"></span><h1>smac.main.boing<a class="headerlink" href="#module-smac.main.boing" title="Permalink to this heading">¶</a></h1>
<p>from __future__ import annotations</p>
<p>from typing import Dict, Iterator, List, Tuple, Type, Union</p>
<p>import copy
from itertools import chain</p>
<p>import numpy as np
from ConfigSpace.hyperparameters import NumericalHyperparameter</p>
<p>from smac.acquisition import AbstractAcquisitionOptimizer
from smac.acquisition.functions import AbstractAcquisitionFunction
from smac.acquisition.functions.expected_improvement import EI
from smac.acquisition.functions.thompson import TS
from ConfigSpace import Configuration
from smac.constants import MAXINT
from smac.main.smbo import SMBO
from smac.model.abstract_model import AbstractModel
from smac.model.gaussian_process.gpytorch_gaussian_process import (</p>
<blockquote>
<div><p>GloballyAugmentedLocalGaussianProcess,</p>
</div></blockquote>
<p>)
from smac.model.random_forest.random_forest import (</p>
<blockquote>
<div><p>RandomForest,</p>
</div></blockquote>
<p>)
from smac.model.utils import get_types
from smac.runhistory.encoder.boing_encoder import RunHistoryRawEncoder
from smac.utils.logging import get_logger
from smac.utils.subspaces.boing_subspace import BOinGSubspace
from smac.utils.subspaces.turbo_subspace import TuRBOSubSpace</p>
<p>__copyright__ = “Copyright 2022, automl.org”
__license__ = “3-clause BSD”</p>
<p>logger = get_logger(__name__)</p>
<dl>
<dt>class BOinGSMBO(SMBO):</dt><dd><p>“””
Interface to train the EPM and generate next configurations with both global and local models.</p>
<dl>
<dt>model_local: Type[BaseModel],</dt><dd><p>local empirical performance model, used in subspace. Since the subspace might have different amount of
hyperparameters compared to the search space. We only instantiate them under the subspace.</p>
</dd>
<dt>model_local_kwargs: Optional[Dict] = None,</dt><dd><p>parameters for initializing a local model</p>
</dd>
<dt>acquisition_func_local: AbstractAcquisitionFunction | Type[AbstractAcquisitionFunction],</dt><dd><p>local acquisition function,  used in subspace</p>
</dd>
<dt>acquisition_func_local_kwargs: Dict | None = None,</dt><dd><p>parameters for initializing a local acquisition function optimizer</p>
</dd>
<dt>acq_optimizer_local: AbstractAcquisitionOptimizer | None = None,</dt><dd><p>Optimizer of acquisition function of local models, same as above, since an acquisition function optimizer
requires</p>
</dd>
<dt>acq_optimizer_local_kwargs: Dict | None = None,</dt><dd><p>parameters for the optimizer of acquisition function of local models</p>
</dd>
<dt>max_configs_local_fracs<span class="classifier">float</span></dt><dd><p>The maximal number of fractions of samples to be included in the subspace. If the number of samples in the
subspace is greater than this value and n_min_config_inner, the subspace will be cropped to fit the</p>
<blockquote>
<div><p>requirement</p>
</div></blockquote>
</dd>
<dt>min_configs_local: int | None,</dt><dd><p>Minimum number of samples included in the inner loop model</p>
</dd>
<dt>do_switching: bool = False</dt><dd><p>if we want to switch between turbo and boing or do a pure BOinG search</p>
</dd>
<dt>turbo_kwargs: Dict | None = None</dt><dd><p>parameters for building a turbo optimizer, for details, please refer to smac.loop.turbo</p>
</dd>
<dt>args:</dt><dd><p>additional arguments for initialize base SMBO object</p>
</dd>
<dt>kwargs:</dt><dd><p>additional arguments for initialize base SMBO object</p>
</dd>
</dl>
<p>“””</p>
<dl>
<dt>def __init__(</dt><dd><p>self,
model_local: Type[AbstractModel] = GloballyAugmentedLocalGaussianProcess,
acquisition_func_local: AbstractAcquisitionFunction | Type[AbstractAcquisitionFunction] = EI,
model_local_kwargs: Dict | None = None,
acquisition_func_local_kwargs: Dict | None = None,
acq_optimizer_local: AbstractAcquisitionOptimizer | None = None,
acq_optimizer_local_kwargs: Dict | None = None,
max_configs_local_fracs: float = 0.5,
min_configs_local: int | None = None,
do_switching: bool = False,
turbo_kwargs: Dict | None = None,
<a href="#id1"><span class="problematic" id="id2">*</span></a>args,
<a href="#id3"><span class="problematic" id="id4">**</span></a>kwargs,</p>
</dd>
<dt>):</dt><dd><p>super(BOinGSMBO, self).__init__(<a href="#id5"><span class="problematic" id="id6">*</span></a>args, <a href="#id7"><span class="problematic" id="id8">**</span></a>kwargs)</p>
<dl class="simple">
<dt>if not isinstance(self.model, RandomForest):</dt><dd><p>raise ValueError(“BOinG only supports RandomForestWithInstances as its global optimizer”)</p>
</dd>
<dt>if not isinstance(self.runhistory_encoder, RunHistoryRawEncoder):</dt><dd><p>raise ValueError(“BOinG only supports RunHistory2EPM4CostWithRaw as its rh transformer”)</p>
</dd>
<dt>self.subspace_info = {</dt><dd><p>“model_local”: model_local,
“model_local_kwargs”: model_local_kwargs,
“acq_func_local”: acquisition_func_local,
“acq_func_local_kwargs”: acquisition_func_local_kwargs,
“acq_optimizer_local”: acq_optimizer_local,
“acq_optimizer_local_kwargs”: acq_optimizer_local_kwargs,</p>
</dd>
</dl>
<p>}</p>
<p>self.max_configs_local_fracs = max_configs_local_fracs
self.min_configs_local = (</p>
<blockquote>
<div><p>min_configs_local if min_configs_local is not None else 5 * len(self.configspace.get_hyperparameters())</p>
</div></blockquote>
<p>)</p>
<p>types, bounds = get_types(self.configspace, instance_features=None)</p>
<p>self.types = types
self.bounds = bounds
self.cat_dims = np.where(np.array(types) != 0)[0]
self.cont_dims = np.where(np.array(types) == 0)[0]</p>
<p>self.frac_to_start_bi = 0.8
self.split_count = np.zeros(len(types))
self.do_switching = do_switching
self.random_search_upper_log = 1</p>
<p>self.optimal_value = np.inf
self.optimal_config = None</p>
<p>self.ss_threshold = 0.1 ** len(self.configspace.get_hyperparameters())
if self.do_switching:</p>
<blockquote>
<div><p># If we want to switch between BOinG and TurBO
self.run_TuRBO = False
self.failcount_BOinG = 0
self.failcount_TuRBO = 0</p>
<p>turbo_model = copy.deepcopy(model_local)
turbo_acq = TS
turbo_opt_kwargs = dict(</p>
<blockquote>
<div><p>config_space=self.configspace,
bounds=bounds,
hps_types=types,
model_local=turbo_model,
model_local_kwargs=copy.deepcopy(model_local_kwargs),
acq_func_local=turbo_acq,
rng=self.rng,
length_min=2e-4,</p>
</div></blockquote>
<p>)
self.turbo_kwargs = turbo_opt_kwargs
if turbo_kwargs is not None:</p>
<blockquote>
<div><p>turbo_opt_kwargs.update(turbo_kwargs)</p>
</div></blockquote>
<p>self.turbo_optimizer = TuRBOSubSpace(<a href="#id9"><span class="problematic" id="id10">**</span></a>turbo_opt_kwargs)</p>
</div></blockquote>
</dd>
<dt>def restart_TuRBOinG(self, X: np.ndarray, Y: np.ndarray, Y_raw: np.ndarray, train_model: bool = False) -&gt; None:</dt><dd><p>“””
Restart a new TurBO Optimizer, the bounds of the TurBO Optimizer is determined by a RF, we randomly sample 20
points and extract subspaces that contain at least self.min_configs_local points, and we select the subspace
with the largest volume to construct a turbo optimizer
Parameters
———-
X: np.ndarray (N, D)</p>
<blockquote>
<div><p>previous evaluated configurations</p>
</div></blockquote>
<dl class="simple">
<dt>Y: np.ndarray (N,)</dt><dd><p>performances of previous evaluated configurations (transformed by rh2epm transformer)</p>
</dd>
<dt>Y_raw: np.ndarray (N,)</dt><dd><p>performances of previous evaluated configurations (raw values, not transformed)</p>
</dd>
<dt>train_model: bool</dt><dd><p>if we retrain the model with the given X and Y</p>
</dd>
</dl>
<p>“””
if train_model:</p>
<blockquote>
<div><p>self.model.train(X, Y)</p>
</div></blockquote>
<p>num_samples = 20
union_ss = []
union_indices = []
rand_samples = self.configspace.sample_configuration(num_samples)
for sample in rand_samples:</p>
<blockquote>
<div><p>sample_array = sample.get_array()
union_bounds_cont, _, ss_data_indices = subspace_extraction(</p>
<blockquote>
<div><p>X=X,
challenger=sample_array,
model=self.model,
num_min=self.min_configs_local,
num_max=MAXINT,
bounds=self.bounds,
cont_dims=self.cont_dims,
cat_dims=self.cat_dims,</p>
</div></blockquote>
<p>)
union_ss.append(union_bounds_cont)
union_indices.append(ss_data_indices)</p>
</div></blockquote>
<p>union_ss = np.asarray(union_ss)
volume_ss = np.product(union_ss[:, :, 1] - union_ss[:, :, 0], axis=1)  # type: ignore
ss_idx = np.argmax(volume_ss)
ss_turbo = union_ss[ss_idx]
ss_data_indices = union_indices[ss_idx]</p>
<p># we only consider numerical(continuous) hyperparameters here
self.turbo_optimizer = TuRBOSubSpace(</p>
<blockquote>
<div><p><a href="#id11"><span class="problematic" id="id12">**</span></a>self.turbo_kwargs,  # type: ignore
bounds_ss_cont=ss_turbo,  # type: ignore
initial_data=(X[ss_data_indices], Y_raw[ss_data_indices]),  # type: ignore</p>
</div></blockquote>
<p>)
self.turbo_optimizer.add_new_observations(X[ss_data_indices], Y_raw[ss_data_indices])</p>
</dd>
<dt>def ask(self) -&gt; Iterator[Configuration]:</dt><dd><p>“””
Choose next candidate solution with Bayesian optimization. We use TurBO optimizer or BOinG to suggest</p>
<blockquote>
<div><p>the next configuration.</p>
</div></blockquote>
<p>If we switch local model between TurBO and BOinG, we gradually increase the probability to switch to another
optimizer if we cannot make further process. (Or if TurBO find a new incumbent, we will switch to BOinG to do
further exploitation)
“””
incumbent_value: float = None</p>
<p># we also need the untransformed raw y values to used for local models
X, Y, Y_raw, X_configurations = self._collect_all_data_to_train_model()
if self.do_switching:</p>
<blockquote>
<div><dl>
<dt>if self.run_TuRBO:</dt><dd><p>X, Y, Y_raw, X_configurations = self._collect_all_data_to_train_model()</p>
<p>num_new_observations = 1  # here we only consider batch_size == 1</p>
<p>new_observations = Y_raw[-num_new_observations:]</p>
<p># give new suggestions from initialized values in TurBO
if len(self.turbo_optimizer.init_configs) &gt; 0:</p>
<blockquote>
<div><p>self.turbo_optimizer.add_new_observations(X[-num_new_observations:], Y_raw[-num_new_observations:])
return self.turbo_optimizer.generate_challengers()</p>
</div></blockquote>
<p>self.turbo_optimizer.adjust_length(new_observations)</p>
<p># if we need to restart TurBO, we first check if we want to switch to BOinG
if self.turbo_optimizer.length &lt; self.turbo_optimizer.length_min:</p>
<blockquote>
<div><p>optimal_turbo = np.min(self.turbo_optimizer.ss_y)</p>
<p>logger.debug(f”Best Found value by TuRBO: {optimal_turbo}”)</p>
<p>increment = optimal_turbo - self.optimal_value</p>
<dl>
<dt>if increment &lt; 0:</dt><dd><p>min_idx = np.argmin(Y_raw)
self.optimal_value = Y_raw[min_idx].item()
# compute the distance between the previous incumbent and new incumbent
cfg_diff = X[min_idx] - self.optimal_config
self.optimal_config = X[min_idx]
# we avoid sticking to a local minimum too often, e.g. either we have a relative much better
# configuration or the new configuration is a little bit far away from the current incumbent
if (</p>
<blockquote>
<div><p>increment &lt; -1e-3 * np.abs(self.optimal_value)
or np.abs(np.product(cfg_diff)) &gt;= self.ss_threshold</p>
</div></blockquote>
<dl class="simple">
<dt>):</dt><dd><p>self.failcount_TuRBO -= 1
# switch to BOinG as TurBO found a better model and we could do exploration
# also we halve the failcount of BOinG to avoid switching to TurBO too frequently
self.failcount_BOinG = self.failcount_BOinG // 2
self.run_TuRBO = False
logger.debug(“Optimizer switches to BOinG!”)</p>
</dd>
</dl>
</dd>
<dt>else:</dt><dd><p>self.failcount_TuRBO += 1</p>
</dd>
</dl>
<p># The probability is a linear curve.
prob_to_BOinG = 0.1 * self.failcount_TuRBO
logger.debug(f”failure_count TuRBO :{self.failcount_TuRBO}”)
rand_value = self.rng.random()</p>
<dl class="simple">
<dt>if rand_value &lt; prob_to_BOinG:</dt><dd><p>self.failcount_BOinG = self.failcount_BOinG // 2
self.run_TuRBO = False
logger.debug(“Optimizer switches to BOinG!”)</p>
</dd>
<dt>else:</dt><dd><p>self.restart_TuRBOinG(X=X, Y=Y, Y_raw=Y_raw, train_model=True)
return self.turbo_optimizer.generate_challengers()</p>
</dd>
</dl>
</div></blockquote>
<p>self.turbo_optimizer.add_new_observations(X[-num_new_observations:], Y_raw[-num_new_observations:])</p>
<p>return self.turbo_optimizer.generate_challengers()</p>
</dd>
</dl>
</div></blockquote>
<p>previous_configs = self.runhistory.get_configs()
if X.shape[0] == 0:</p>
<blockquote>
<div><p># Only return a single point to avoid an overly high number of
# random search iterations
return iter([self.configspace.sample_configuration(1)])</p>
</div></blockquote>
<p># if the number of points is not big enough, we simply build one subspace (the raw configuration space) and
# the local model becomes global model
if X.shape[0] &lt; (self.min_configs_local / self.frac_to_start_bi):</p>
<blockquote>
<div><dl>
<dt>if len(self.configspace.get_conditions()) == 0:</dt><dd><p>self.model.train(X, Y)
cs = self.scenario.configspace  # type: ignore
ss = BOinGSubspace(</p>
<blockquote>
<div><p>config_space=cs,
bounds=self.bounds,
hps_types=self.types,
rng=self.rng,
initial_data=(X, Y_raw),
incumbent_array=None,
model_local=self.subspace_info[“model_local”],  # type: ignore
model_local_kwargs=self.subspace_info[“model_local_kwargs”],  # type: ignore
acq_func_local=self.subspace_info[“acq_func_local”],  # type: ignore
acq_func_local_kwargs=self.subspace_info[“acq_func_local_kwargs”],  # type: ignore
acq_optimizer_local=self.acquisition_optimizer,</p>
</div></blockquote>
<p>)
return ss.generate_challengers()</p>
</dd>
</dl>
</div></blockquote>
<p># train the outer model
self.model.train(X, Y)</p>
<dl>
<dt>if incumbent_value is not None:</dt><dd><p>best_observation = incumbent_value
x_best_array = None  # type: np.ndarray | None</p>
</dd>
<dt>else:</dt><dd><dl class="simple">
<dt>if self.runhistory.empty():</dt><dd><p>raise ValueError(“Runhistory is empty and the cost value of ” “the incumbent is unknown.”)</p>
</dd>
</dl>
<p>x_best_array, best_observation = self._get_x_best(self.predict_x_best, X_configurations)</p>
</dd>
<dt>self.acquisition_function.update(</dt><dd><p>model=self.model,
eta=best_observation,
incumbent_array=x_best_array,
num_data=len(self._get_evaluated_configs()),
X=X_configurations,</p>
</dd>
</dl>
<p>)</p>
<dl>
<dt>if self.do_switching:</dt><dd><p># check if we need to switch to turbo
# same as above
self.failcount_BOinG += 1
increment = Y_raw[-1].item() - self.optimal_value
if increment &lt; 0:</p>
<blockquote>
<div><dl>
<dt>if self.optimal_config is not None:</dt><dd><p>cfg_diff = X[-1] - self.optimal_config
if (</p>
<blockquote>
<div><p>increment &lt; -1e-2 * np.abs(self.optimal_value)
or np.abs(np.product(cfg_diff)) &gt;= self.ss_threshold</p>
</div></blockquote>
<dl class="simple">
<dt>):</dt><dd><p>self.failcount_BOinG -= X.shape[-1]</p>
</dd>
</dl>
<p>self.optimal_value = Y_raw[-1].item()
self.optimal_config = X[-1]</p>
</dd>
<dt>else:</dt><dd><p># restart
idx_min = np.argmin(Y_raw)
logger.debug(“Better value found by BOinG, continue BOinG”)
self.optimal_value = Y_raw[idx_min].item()
self.optimal_config = X[idx_min]
self.failcount_BOinG = 0</p>
</dd>
</dl>
</div></blockquote>
<p># similar to TurBO, we do a judgement every n_dimension times
amplify_param = self.failcount_BOinG // (X.shape[-1] * 1)</p>
<dl>
<dt>if self.failcount_BOinG % (X.shape[-1] * 1) == 0:</dt><dd><p>prob_to_TurBO = 0.1 * amplify_param
rand_value = self.rng.random()</p>
<dl class="simple">
<dt>if rand_value &lt; prob_to_TurBO:</dt><dd><p>self.run_TuRBO = True
logger.debug(“Switch To TuRBO”)
self.failcount_TuRBO = self.failcount_TuRBO // 2
self.restart_TuRBOinG(X=X, Y=Y, Y_raw=Y_raw, train_model=False)</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>challengers_global = self.acquisition_optimizer.maximize(</dt><dd><p>previous_configs,
random_design=self.random_design,</p>
</dd>
</dl>
<p>)</p>
<dl class="simple">
<dt>if (</dt><dd><p>X.shape[0] &lt; (self.min_configs_local / self.frac_to_start_bi)
and len(self.configspace.get_conditions()) == 0</p>
</dd>
<dt>):</dt><dd><p>return challengers_global</p>
</dd>
</dl>
<p>cfg_challenger_global_first = next(challengers_global)
array_challenger_global_first = cfg_challenger_global_first.get_array()  # type: np.ndarray</p>
<p>num_max_configs = int(X.shape[0] * self.max_configs_local_fracs)</p>
<p># to avoid the case that num_max_configs is only a little larger than self.min_configs_local
num_max = MAXINT if num_max_configs &lt;= 2 * self.min_configs_local else num_max_configs</p>
<dl>
<dt>if len(self.configspace.get_conditions()) &gt; 0:</dt><dd><p>challanger_activate_hps = np.isfinite(array_challenger_global_first).astype(int)
rh_activate_hps = np.isfinite(X).astype(int)
indices_X_in_same_hierarchy = np.all((challanger_activate_hps - rh_activate_hps) == 0, axis=1)
num_indices_X_in_same_hierarchy = sum(indices_X_in_same_hierarchy)</p>
<dl class="simple">
<dt>if num_indices_X_in_same_hierarchy == 0:</dt><dd><p>return chain([cfg_challenger_global_first], challengers_global)</p>
</dd>
</dl>
<p>activate_dims = []
hps = self.configspace.get_hyperparameters()
for idx_hp in np.where(challanger_activate_hps &gt; 0)[0]:</p>
<blockquote>
<div><dl>
<dt>if isinstance(hps[idx_hp], NumericalHyperparameter):</dt><dd><p>activate_dims.append(idx_hp)</p>
</dd>
<dt>else:</dt><dd><dl class="simple">
<dt>indices_X_in_same_hierarchy = indices_X_in_same_hierarchy &amp; (</dt><dd><p>X[:, idx_hp] == array_challenger_global_first[idx_hp]</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
</div></blockquote>
<p>num_indices_X_in_same_hierarchy = sum(indices_X_in_same_hierarchy)</p>
<p>X = X[indices_X_in_same_hierarchy]
Y_raw = Y_raw[indices_X_in_same_hierarchy]</p>
<dl class="simple">
<dt>if len(activate_dims) == 0 or num_indices_X_in_same_hierarchy &lt;= max(5, len(activate_dims)):</dt><dd><p>return chain([cfg_challenger_global_first], challengers_global)</p>
</dd>
</dl>
<p>n_min_configs_inner = self.min_configs_local // len(hps) * len(activate_dims)</p>
</dd>
<dt>else:</dt><dd><p>n_min_configs_inner = self.min_configs_local
activate_dims = np.arange(len(self.configspace.get_hyperparameters()))</p>
</dd>
<dt>bounds_ss_cont, bounds_ss_cat, ss_data_indices = subspace_extraction(</dt><dd><p>X=X,
challenger=array_challenger_global_first,
model=self.model,  # type: ignore[arg-type]
num_min=n_min_configs_inner,
num_max=num_max,
bounds=self.bounds,
cont_dims=self.cont_dims,
cat_dims=self.cat_dims,</p>
</dd>
</dl>
<p>)</p>
<p>logger.debug(“contained {0} data of {1}”.format(sum(ss_data_indices), Y_raw.size))</p>
<dl class="simple">
<dt>ss = BOinGSubspace(</dt><dd><p>config_space=self.configspace,
bounds=self.bounds,
hps_types=self.types,
bounds_ss_cont=bounds_ss_cont,  # type: ignore[arg-type]
bounds_ss_cat=bounds_ss_cat,
rng=self.rng,
initial_data=(X, Y_raw),
incumbent_array=array_challenger_global_first,  # type: ignore[arg-type]
activate_dims=activate_dims,
<a href="#id13"><span class="problematic" id="id14">**</span></a>self.subspace_info,  # type: ignore[arg-type]</p>
</dd>
</dl>
<p>)
return ss.generate_challengers()</p>
</dd>
<dt>def _collect_all_data_to_train_model(self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:</dt><dd><p>“””
Similar to the implementation of SMBO. However, we also return the raw target values (before transformation).
“””
# if we use a float value as a budget, we want to train the model only on the highest budget
available_budgets = []
for run_key in self.runhistory.data.keys():</p>
<blockquote>
<div><p>available_budgets.append(run_key.budget)</p>
</div></blockquote>
<p># Sort available budgets from highest to lowest budget
available_budgets = sorted(list(set(available_budgets)), reverse=True)</p>
<p># Get #points per budget and if there are enough samples, then build a model
for b in available_budgets:</p>
<blockquote>
<div><dl>
<dt>X, Y, Y_raw = self.runhistory_encoder.transform_with_raw(  # type: ignore[attr-defined]</dt><dd><p>self.runhistory,
budget_subset=[</p>
<blockquote>
<div><p>b,</p>
</div></blockquote>
<p>],</p>
</dd>
</dl>
<p>)  # type: ignore
if X.shape[0] &gt;= self.min_samples_model:</p>
<blockquote>
<div><dl class="simple">
<dt>self.currently_considered_budgets = [</dt><dd><p>b,</p>
</dd>
</dl>
<p>]
configs_array = self.runhistory_encoder.get_configurations(</p>
<blockquote>
<div><p>self.runhistory, budget_subset=self.currently_considered_budgets</p>
</div></blockquote>
<p>)
return X, Y, Y_raw, configs_array</p>
</div></blockquote>
</div></blockquote>
<dl>
<dt>return (</dt><dd><p>np.empty(shape=[0, 0]),
np.empty(</p>
<blockquote>
<div><dl class="simple">
<dt>shape=[</dt><dd><p>0,</p>
</dd>
</dl>
<p>]</p>
</div></blockquote>
<p>),
np.empty(</p>
<blockquote>
<div><dl class="simple">
<dt>shape=[</dt><dd><p>0,</p>
</dd>
</dl>
<p>]</p>
</div></blockquote>
<p>),
np.empty(shape=[0, 0]),</p>
</dd>
</dl>
<p>)</p>
</dd>
</dl>
</dd>
<dt>def subspace_extraction(</dt><dd><p>X: np.ndarray,
challenger: np.ndarray,
model: RandomForest,
num_min: int,
num_max: int,
bounds: np.ndarray | List[Tuple],
cat_dims: np.ndarray,
cont_dims: np.ndarray,</p>
</dd>
<dt>) -&gt; Tuple[np.ndarray, List[Tuple], np.ndarray]:</dt><dd><p>“””
Extract a subspace that contains at least num_min points but no more than num_max points</p>
<dl class="simple">
<dt>X: np.ndarray (N, D)</dt><dd><p>points used to train the model</p>
</dd>
<dt>challenger: np.ndarray (1, D)</dt><dd><p>the challenger where the subspace would grow</p>
</dd>
<dt>model: RandomForestWithInstances</dt><dd><p>a rf model</p>
</dd>
<dt>num_min: int</dt><dd><p>minimal number of points to be included in the subspace</p>
</dd>
<dt>num_max: int</dt><dd><p>maximal number of points to be included in the subspace</p>
</dd>
<dt>bounds: np.ndarray(D, 2)</dt><dd><p>bounds of the entire space, D = D_cat + D_cont</p>
</dd>
<dt>cat_dims: np.ndarray (D_cat)</dt><dd><p>categorical dimensions</p>
</dd>
</dl>
<p>cont_dims: np.ndarray(D_cont)
continuous dimensions</p>
<dl class="simple">
<dt>union_bounds_cont: np.ndarray(D_cont, 2),</dt><dd><p>the continuous bounds of the subregion</p>
</dd>
<dt>union_bounds_cat, List[Tuple],</dt><dd><p>the categorical bounds of the subregion</p>
</dd>
<dt>in_ss_dims:</dt><dd><p>indices of the points that lie inside the subregion</p>
</dd>
</dl>
<p>“””
trees = model.rf.get_all_trees()
trees = [tree for tree in trees]
num_trees = len(trees)
node_indices = [0] * num_trees</p>
<p>indices_trees = np.arange(num_trees)
np.random.shuffle(indices_trees)
ss_indices = np.full(X.shape[0], True)  # type: np.ndarray</p>
<p>stop_update = [False] * num_trees</p>
<p>ss_bounds = np.array(bounds)</p>
<p>cont_dims = np.array(cont_dims)
cat_dims = np.array(cat_dims)</p>
<dl>
<dt>if len(cat_dims) == 0:</dt><dd><p>ss_bounds_cat = [()]</p>
</dd>
<dt>else:</dt><dd><p>ss_bounds_cat = [() for _ in range(len(cat_dims))]
for i, cat_dim in enumerate(cat_dims):</p>
<blockquote>
<div><p>ss_bounds_cat[i] = np.arange(ss_bounds[cat_dim][0])</p>
</div></blockquote>
</dd>
<dt>if len(cont_dims) == 0:</dt><dd><p>ss_bounds_cont = np.array([])  # type: np.ndarray</p>
</dd>
<dt>else:</dt><dd><p>ss_bounds_cont = ss_bounds[cont_dims]</p>
</dd>
<dt>def traverse_forest(check_num_min: bool = True) -&gt; None:</dt><dd><p>nonlocal ss_indices
np.random.shuffle(indices_trees)
for i in indices_trees:</p>
<blockquote>
<div><dl class="simple">
<dt>if stop_update[i]:</dt><dd><p>continue</p>
</dd>
</dl>
<p>tree = trees[int(i)]
node_idx = node_indices[i]
node = tree.get_node(node_idx)</p>
<dl class="simple">
<dt>if node.is_a_leaf():</dt><dd><p>stop_update[i] = True
continue</p>
</dd>
</dl>
<p>feature_idx = node.get_feature_index()
cont_feature_idx = np.where(feature_idx == cont_dims)[0]
if cont_feature_idx.size == 0:</p>
<blockquote>
<div><p># This node split the subspace w.r.t. the categorical hyperparameters
cat_feature_idx = np.where(feature_idx == cat_dims)[0][0]
split_value = node.get_cat_split()
intersect = np.intersect1d(ss_bounds_cat[cat_feature_idx], split_value, assume_unique=True)</p>
<dl class="simple">
<dt>if len(intersect) == len(ss_bounds_cat[cat_feature_idx]):</dt><dd><p># will fall into the left child
temp_child_idx = 0
node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
<dt>elif len(intersect) == 0:</dt><dd><p># will fall into the left child
temp_child_idx = 1
node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
<dt>else:</dt><dd><dl class="simple">
<dt>if challenger[feature_idx] in intersect:</dt><dd><p>temp_child_idx = 0
temp_node_indices = ss_indices &amp; np.in1d(X[:, feature_idx], split_value)
temp_bound_ss = intersect</p>
</dd>
<dt>else:</dt><dd><p>temp_child_idx = 1
temp_node_indices = ss_indices &amp; np.in1d(X[:, feature_idx], split_value, invert=True)
temp_bound_ss = np.setdiff1d(ss_bounds_cat[cat_feature_idx], split_value)</p>
</dd>
<dt>if sum(temp_node_indices) &gt; num_min:</dt><dd><p># number of points inside subspace is still greater than num_min, we could go deeper
ss_bounds_cat[cat_feature_idx] = temp_bound_ss
ss_indices = temp_node_indices
node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
<dt>else:</dt><dd><dl class="simple">
<dt>if check_num_min:</dt><dd><p>stop_update[i] = True</p>
</dd>
<dt>else:</dt><dd><p># if we don’t check the num_min, we will stay go deeper into the child nodes without
# splitting the subspace
node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>else:</dt><dd><p># This node split the subspace w.r.t. the continuous hyperparameters
split_value = node.get_num_split_value()
cont_feature_idx = cont_feature_idx.item()
if ss_bounds_cont[cont_feature_idx][0] &lt;= split_value &lt;= ss_bounds_cont[cont_feature_idx][1]:</p>
<blockquote>
<div><p># the subspace can be further split
if challenger[feature_idx] &gt;= split_value:</p>
<blockquote>
<div><p>temp_bound_ss = np.array([split_value, ss_bounds_cont[cont_feature_idx][1]])
temp_node_indices = ss_indices &amp; (X[:, feature_idx] &gt;= split_value)
temp_child_idx = 1</p>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>temp_bound_ss = np.array([ss_bounds_cont[cont_feature_idx][0], split_value])
temp_node_indices = ss_indices &amp; (X[:, feature_idx] &lt;= split_value)
temp_child_idx = 0</p>
</dd>
<dt>if sum(temp_node_indices) &gt; num_min:</dt><dd><p># number of points inside subspace is still greater than num_min
ss_bounds_cont[cont_feature_idx] = temp_bound_ss
ss_indices = temp_node_indices
node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
<dt>else:</dt><dd><dl class="simple">
<dt>if check_num_min:</dt><dd><p>stop_update[i] = True</p>
</dd>
<dt>else:</dt><dd><p>node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>else:</dt><dd><p>temp_child_idx = 1 if challenger[feature_idx] &gt;= split_value else 0
node_indices[i] = node.get_child_index(temp_child_idx)</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
</dd>
<dt>while sum(stop_update) &lt; num_trees:</dt><dd><p>traverse_forest()</p>
</dd>
<dt>if sum(ss_indices) &gt; num_max:</dt><dd><p># number of points inside the subregion have a larger value than num_max
stop_update = [False] * num_trees
while sum(stop_update) &lt; num_trees:</p>
<blockquote>
<div><p>traverse_forest(False)</p>
</div></blockquote>
</dd>
</dl>
<p>return ss_bounds_cont, ss_bounds_cat, ss_indices  # type: ignore[return-value]</p>
</dd>
</dl>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="smac.main.base_smbo.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">smac.main.base_smbo</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="smac.main.smbo.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">smac.main.smbo</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.9ea38e314b9e6d9dab77.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 
    Copyright 2022, Marius Lindauer, Katharina Eggensperger,
    Matthias Feurer, André Biedenkapp, Difan Deng, Carolin Benjamins, Tim Ruhkopf, René Sass
    and Frank Hutter
.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a>
5.1.1. Template is modified version of <a
href="https://pydata-sphinx-theme.readthedocs.io">PyData Sphinx Theme</a>. <br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>