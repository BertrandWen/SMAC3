
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/1_basics/3_ask_and_tell.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_1_basics_3_ask_and_tell.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_1_basics_3_ask_and_tell.py:


Ask-and-Tell
^^^^^^^^^^^^

This examples show how to use the Ask-and-Tell interface.

.. GENERATED FROM PYTHON SOURCE LINES 7-82




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [INFO][abstract_initial_design.py:81] Reducing the number of initial configurations from 20 to 10 (max_ratio == 0.1).
    [INFO][abstract_initial_design.py:133] Using 10 initial design and 0 additional configurations.
    [INFO][intensifier.py:275] No incumbent provided in the first run. Sampling a new challenger...
    [INFO][intensifier.py:446] First run and no incumbent provided. Challenger is assumed to be the incumbent.
    [INFO][intensifier.py:567] Updated estimated cost of incumbent on 1 trials: 1102.7878
    [INFO][abstract_intensifier.py:340] Challenger (700.6438) is better than incumbent (1102.7878) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -0.9968221839517355 -> -0.0801787059894652
    [INFO][abstract_intensifier.py:367] --- x1: 4.30847043171525 -> 2.6511913893559456
    [INFO][abstract_intensifier.py:340] Challenger (47.8624) is better than incumbent (700.6438) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -0.0801787059894652 -> -1.6583473885830928
    [INFO][abstract_intensifier.py:367] --- x1: 2.6511913893559456 -> 2.111401430503671
    [INFO][abstract_intensifier.py:340] Challenger (10.9601) is better than incumbent (47.8624) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -1.6583473885830928 -> -1.5234560660524123
    [INFO][abstract_intensifier.py:367] --- x1: 2.111401430503671 -> 2.106623106617114
    [INFO][abstract_intensifier.py:340] Challenger (4.1317) is better than incumbent (10.9601) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -1.5234560660524123 -> -1.0139112945122775
    [INFO][abstract_intensifier.py:367] --- x1: 2.106623106617114 -> 1.0004718388428309
    [INFO][abstract_intensifier.py:340] Challenger (3.9908) is better than incumbent (4.1317) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -1.0139112945122775 -> -0.9892633340334083
    [INFO][abstract_intensifier.py:367] --- x1: 1.0004718388428309 -> 0.9969769489049165
    [INFO][abstract_intensifier.py:340] Challenger (3.99) is better than incumbent (3.9908) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -0.9892633340334083 -> -0.9930450352207787
    [INFO][abstract_intensifier.py:367] --- x1: 0.9969769489049165 -> 0.9994799142372051
    [INFO][abstract_intensifier.py:340] Challenger (3.9881) is better than incumbent (3.99) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x1: 0.9994799142372051 -> 0.9987380639014205
    [INFO][abstract_intensifier.py:340] Challenger (3.987) is better than incumbent (3.9881) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -0.9930450352207787 -> -0.9967287661480402
    [INFO][abstract_intensifier.py:367] --- x1: 0.9987380639014205 -> 0.9927965529154807
    [INFO][abstract_intensifier.py:340] Challenger (3.9752) is better than incumbent (3.987) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -0.9967287661480402 -> -0.9930450352207787
    [INFO][abstract_intensifier.py:367] --- x1: 0.9927965529154807 -> 0.9807044715008999
    [INFO][abstract_intensifier.py:340] Challenger (3.9576) is better than incumbent (3.9752) on 1 trials.
    [INFO][abstract_intensifier.py:364] Changes in incumbent:
    [INFO][abstract_intensifier.py:367] --- x0: -0.9930450352207787 -> -0.9876944770105229
    [INFO][abstract_intensifier.py:367] --- x1: 0.9807044715008999 -> 0.9836920787318091
    [INFO][base_smbo.py:260] Configuration budget is exhausted.
    [INFO][abstract_facade.py:314] Final Incumbent: {'x0': -0.9876944770105229, 'x1': 0.9836920787318091}
    [INFO][abstract_facade.py:315] Estimated cost: 3.9575743532947247
    Default cost: 16916.0
    Default cost: 3.9575743532947247






|

.. code-block:: default


    from ConfigSpace import Configuration, ConfigurationSpace, Float

    from smac import HyperparameterOptimizationFacade, Scenario
    from smac.runhistory.dataclasses import TrialValue

    __copyright__ = "Copyright 2021, AutoML.org Freiburg-Hannover"
    __license__ = "3-clause BSD"


    class Rosenbrock2D:
        @property
        def configspace(self) -> ConfigurationSpace:
            cs = ConfigurationSpace(seed=0)
            x0 = Float("x0", (-5, 10), default=-3)
            x1 = Float("x1", (-5, 10), default=-4)
            cs.add_hyperparameters([x0, x1])

            return cs

        def train(self, config: Configuration, seed: int = 0) -> float:
            """The 2-dimensional Rosenbrock function as a toy model.
            The Rosenbrock function is well know in the optimization community and
            often serves as a toy problem. It can be defined for arbitrary
            dimensions. The minimium is always at x_i = 1 with a function value of
            zero. All input parameters are continuous. The search domain for
            all x's is the interval [-5, 10].
            """
            x1 = config["x0"]
            x2 = config["x1"]

            cost = 100.0 * (x2 - x1**2.0) ** 2.0 + (1 - x1) ** 2.0
            return cost


    if __name__ == "__main__":
        model = Rosenbrock2D()

        # Scenario object
        scenario = Scenario(model.configspace, deterministic=False, n_trials=100)

        intensifier = HyperparameterOptimizationFacade.get_intensifier(
            scenario,
            max_config_calls=1,  # We basically use one seed only
        )

        # Now we use SMAC to find the best hyperparameters
        smac = HyperparameterOptimizationFacade(
            scenario,
            model.train,
            intensifier=intensifier,
            overwrite=True,
        )

        # We can ask SMAC which trials should be evaluated next
        for _ in range(10):
            info = smac.ask()
            assert info.seed is not None

            cost = model.train(info.config, seed=info.seed)
            value = TrialValue(cost=cost, time=0.5)

            smac.tell(info, value)

        # After calling ask+tell, we can still optimize
        incumbent = smac.optimize()
        assert smac.stats.finished == 100

        # Get cost of default configuration
        default_cost = smac.validate(model.configspace.get_default_configuration())
        print(f"Default cost: {default_cost}")

        # Let's calculate the cost of the incumbent
        incumbent_cost = smac.validate(incumbent)
        print(f"Default cost: {incumbent_cost}")


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  28.011 seconds)


.. _sphx_glr_download_examples_1_basics_3_ask_and_tell.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 3_ask_and_tell.py <3_ask_and_tell.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 3_ask_and_tell.ipynb <3_ask_and_tell.ipynb>`
