
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/1_basics/1_synthetic_function.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_1_basics_1_synthetic_function.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_1_basics_1_synthetic_function.py:


Synthetic Function
^^^^^^^^^^^^^^^^^^

An example of applying SMAC to optimize a synthetic function (2D Rosenbrock function).

We use the black-box facade because it is designed for black-box function optimization.
The black-box facade uses a :term:`Gaussian Process<GP>` as its surrogate model.
The facade works best on a numerical hyperparameter configuration space and should not
be applied to problems with large evaluation budgets (up to 1000 evaluations).

.. GENERATED FROM PYTHON SOURCE LINES 12-66




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Default value: 16916.0
    [INFO][abstract_initial_design.py:92] Using `n_configs_per_hyperparameter` and ignoring `configs` and `n_configs`.
    [INFO][abstract_initial_design.py:144] Using 20 initial design configurations.
    [INFO][intensification.py:248] No incumbent provided in the first run. Sampling a new challenger...
    [INFO][intensification.py:423] First run and no incumbent provided. Challenger is assumed to be the incumbent.
    [INFO][intensification.py:558] Updated estimated cost of incumbent on 1 trials: 1102.7878
    [INFO][intensification.py:558] Updated estimated cost of incumbent on 2 trials: 1102.7878
    [INFO][intensification.py:558] Updated estimated cost of incumbent on 3 trials: 1102.7878
    [INFO][abstract_intensifier.py:335] Challenger (5.4656) is better than incumbent (1102.7878) on 3 trials.
    [INFO][abstract_intensifier.py:359] Changes in incumbent:
    [INFO][abstract_intensifier.py:362] --- x0: -0.9968221839517355 -> 0.03135360777378082
    [INFO][abstract_intensifier.py:362] --- x1: 4.30847043171525 -> -0.21179260686039925
    [INFO][abstract_intensifier.py:335] Challenger (4.9344) is better than incumbent (5.4656) on 3 trials.
    [INFO][abstract_intensifier.py:359] Changes in incumbent:
    [INFO][abstract_intensifier.py:362] --- x0: 0.03135360777378082 -> 3.1521441831066923
    [INFO][abstract_intensifier.py:362] --- x1: -0.21179260686039925 -> 9.991027821936083
    [INFO][abstract_intensifier.py:335] Challenger (3.1692) is better than incumbent (4.9344) on 3 trials.
    [INFO][abstract_intensifier.py:359] Changes in incumbent:
    [INFO][abstract_intensifier.py:362] --- x0: 3.1521441831066923 -> 1.4106696064172155
    [INFO][abstract_intensifier.py:362] --- x1: 9.991027821936083 -> 1.8167666169669126
    [INFO][abstract_intensifier.py:335] Challenger (2.144) is better than incumbent (3.1692) on 3 trials.
    [INFO][abstract_intensifier.py:359] Changes in incumbent:
    [INFO][abstract_intensifier.py:362] --- x0: 1.4106696064172155 -> 1.403706808083208
    [INFO][abstract_intensifier.py:362] --- x1: 1.8167666169669126 -> 1.82964389327294
    [INFO][abstract_intensifier.py:335] Challenger (1.5901) is better than incumbent (2.144) on 3 trials.
    [INFO][abstract_intensifier.py:359] Changes in incumbent:
    [INFO][abstract_intensifier.py:362] --- x0: 1.403706808083208 -> 1.395035485965658
    [INFO][abstract_intensifier.py:362] --- x1: 1.82964389327294 -> 1.8263728258094574
    [INFO][abstract_intensifier.py:335] Challenger (0.8351) is better than incumbent (1.5901) on 3 trials.
    [INFO][abstract_intensifier.py:359] Changes in incumbent:
    [INFO][abstract_intensifier.py:362] --- x0: 1.395035485965658 -> 1.7031544591929872
    [INFO][abstract_intensifier.py:362] --- x1: 1.8263728258094574 -> 2.842364243857716
    [INFO][facade.py:269] Final Incumbent: {'x0': 1.7031544591929872, 'x1': 2.842364243857716}
    [INFO][facade.py:270] Estimated cost: 0.8351420167215506
    Incumbent value: 0.84






|

.. code-block:: default


    from ConfigSpace import Configuration, ConfigurationSpace, Float

    from smac import BlackBoxFacade, Scenario

    __copyright__ = "Copyright 2021, AutoML.org Freiburg-Hannover"
    __license__ = "3-clause BSD"


    class Rosenbrock2D:
        @property
        def configspace(self) -> ConfigurationSpace:
            cs = ConfigurationSpace(seed=0)
            x0 = Float("x0", (-5, 10), default=-3)
            x1 = Float("x1", (-5, 10), default=-4)
            cs.add_hyperparameters([x0, x1])

            return cs

        def train(self, config: Configuration, seed: int = 0) -> float:
            """The 2-dimensional Rosenbrock function as a toy model.
            The Rosenbrock function is well-known in the optimization community and
            often serves as a toy problem. It can be defined for arbitrary
            dimensions. The minimum is always at x_i = 1 with a function value of
            zero. All input parameters are continuous. The search domain for
            all x's is the interval [-5, 10].
            """
            x1 = config["x0"]
            x2 = config["x1"]

            cost = 100.0 * (x2 - x1**2.0) ** 2.0 + (1 - x1) ** 2.0
            return cost


    if __name__ == "__main__":
        model = Rosenbrock2D()

        # Scenario object specifying the optimization "environment"
        scenario = Scenario(model.configspace, n_trials=300)

        # Example call of the target algorithm (for debugging)
        default_value = model.train(model.configspace.get_default_configuration())
        print(f"Default value: {round(default_value, 2)}")

        # Now we use SMAC to find the best hyperparameters
        smac = BlackBoxFacade(
            scenario,
            model.train,  # We pass the target algorithm here
            overwrite=True,  # Overrides any previous results that are found that are inconsistent with the meta-data.
        )
        incumbent = smac.optimize()

        incumbent_value = model.train(incumbent)
        print(f"Incumbent value: {round(incumbent_value, 2)}")


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  2.424 seconds)


.. _sphx_glr_download_examples_1_basics_1_synthetic_function.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 1_synthetic_function.py <1_synthetic_function.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 1_synthetic_function.ipynb <1_synthetic_function.ipynb>`
